{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step to create the data:\n",
    "- make sure that in the folder `raw_data` there is a file `NYCTAXI202401-202403_OD.zip`\n",
    "- cd to the folder `raw_data`\n",
    "- linux shell `unzip NYCTAXI202401-202403_OD.zip`\n",
    "- run the following notebook\n",
    "- the output will be saved in the folder `data`, which will have two folders `total` and `timeperiod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "if not os.path.exists(\"data/timeperiod\"):\n",
    "    os.makedirs(\"data/timeperiod\")\n",
    "if not os.path.exists(\"data/total\"):\n",
    "    os.makedirs(\"data/total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.read_csv('raw_data/NYCTAXI202401-202403_OD/NYCTAXI202401-202403.geo')\n",
    "print(geo.shape)\n",
    "geo.head( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = pd.read_csv('raw_data/NYCTAXI202401-202403_OD/NYCTAXI202401-202403.rel')\n",
    "print(rel.shape)\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = pd.read_csv('raw_data/NYCTAXI202401-202403_OD/NYCTAXI202401-202403.od')#.drop([\"type\"],axis=1)\n",
    "print(od.shape)\n",
    "od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od[\"flow\"].value_counts().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get two kind of network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network group by time interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        早高峰时段（7:00 - 9:00）\t上班、上学的高峰期。\n",
    "        上午时段（9:00 - 12:00）\t早高峰过后到中午的时间段。\n",
    "        午间时段（12:00 - 14:00）\t中午吃饭和午休时间。\n",
    "        下午时段（14:00 - 17:00）\t午休结束到晚高峰前的时间段。\n",
    "        晚高峰时段（17:00 - 19:00）\t下班、下学的高峰期。\n",
    "        晚间时段（19:00 - 7:00）\t晚高峰过后到第二天早高峰前的时间段。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "od[\"time\"] = pd.to_datetime(od[\"time\"])\n",
    "od[\"hour\"] = od[\"time\"].dt.hour\n",
    "od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the boundaries of the time periods\n",
    "bins = [0, 7, 9, 12, 14, 17, 19, 24]\n",
    "\n",
    "# Define the labels for the time periods\n",
    "labels = ['Night', 'Morning Rush', 'Morning', 'Noon', 'Afternoon', 'Evening Rush', 'Night']\n",
    "# num_labels = [0,1,2,3,4,5,0]\n",
    "\n",
    "tmp = od.copy(deep =True)\n",
    "tmp['time_period'] = pd.cut(tmp['hour'], bins=bins, labels=labels, right=False,ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels:\n",
    "    tmp = tmp.groupby(\"time_period\").get_group(\"Morning Rush\")\n",
    "    tmp.groupby([\"origin_id\",\"destination_id\"]).agg({\"flow\":\"mean\"}).reset_index()\n",
    "    tmp[\"cost\"] = rel[\"cost\"]\n",
    "    tmp.to_csv(f\"data/timeperiod/NYCTAXI_OD_{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_flow_nozero = od[od[\"flow\"]>0].reset_index(drop=True)\n",
    "\n",
    "# # Define the boundaries of the time periods\n",
    "# bins = [0, 7, 9, 12, 14, 17, 19, 24]\n",
    "\n",
    "# # Define the labels for the time periods\n",
    "# labels = ['Night', 'Morning Rush', 'Morning', 'Noon', 'Afternoon', 'Evening Rush', 'Night']\n",
    "# # num_labels = [0,1,2,3,4,5,0]\n",
    "\n",
    "# # Create a new column that groups hours into time periods\n",
    "# od_flow_nozero['time_period'] = pd.cut(od_flow_nozero['hour'], bins=bins, labels=labels, right=False,ordered=False)\n",
    "\n",
    "# # Use the groupby function to group by the new column\n",
    "# od_flow_nozero_agg = od_flow_nozero.groupby([\"time_period\",\"origin_id\",\"destination_id\"]).agg({\"flow\": [\"count\",\"sum\",\"mean\"]}).reset_index()\n",
    "\n",
    "# od_flow_nozero_agg = od_flow_nozero_agg.loc[od_flow_nozero_agg[\"flow\"][\"count\"]!=0,:]\n",
    "\n",
    "# od_flow_nozero_f = od_flow_nozero_agg.copy(deep=True)\n",
    "# od_flow_nozero_f.columns = [\"time_period\",\"origin_id\",\"destination_id\",\"count\",\"sum\",\"mean\"]\n",
    "# od_flow_nozero_f.drop([\"count\",\"sum\"],axis=1,inplace=True)\n",
    "# od_flow_nozero_f.rename(columns={\"mean\":\"mean_flow\"},inplace = True)\n",
    "# od_flow_nozero_f\n",
    "\n",
    "# od_flow_nozero_f.to_csv(\"data/NYCTAXI_OD_timeperiod.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total flow network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agg od by time   -> data/NYCTAXI_OD_agg.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_agg = od.groupby([\"origin_id\",\"destination_id\"]).agg({\"flow\":\"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_agg.to_csv(\"data/NYCTAXI_OD_agg.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join od_agg and rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_agg = pd.read_csv(\"data/NYCTAXI_OD_agg.csv\")\n",
    "od_f = od_agg.copy(deep = True)\n",
    "\n",
    "od_f[\"cost\"] = rel[\"cost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_f.to_csv(\"data/total/NYCTAXI_OD_Total.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add location to the od_f --- not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_f_merge = pd.merge(od_f,geo,left_on=\"origin_id\",right_on=\"geo_id\",how=\"left\").drop([\"geo_id\",\"type\"],axis=1)\\\n",
    "#     .rename(columns={\"coordinates\":\"origin_coordinates\"})\n",
    "# od_f_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_f_merge = pd.merge(od_f_merge,geo,left_on=\"destination_id\",right_on=\"geo_id\",how=\"left\").drop([\"geo_id\",\"type\"],axis=1)\\\n",
    "#     .rename(columns={\"coordinates\":\"destination_coordinates\"})\n",
    "# od_f_merge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
